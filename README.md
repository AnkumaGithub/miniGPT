# miniGPT
Здесь будет написана мини версия gpt (наверное от 10 до 100 млн параметров)    
Архитектура основана на gpt 2, но уже есть отклонения и их количество будет увеличиваться    
Обучаться будет на урезанной(где-то 1/8 часть) версии openwebtext на rtx 3060, 32 gb ram, intel i5(11 поколения)
